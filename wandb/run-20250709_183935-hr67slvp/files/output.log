LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(

  | Name  | Type | Params | Mode
---------------------------------------
0 | model | E2E  | 238 M  | train
---------------------------------------
238 M     Trainable params
0         Non-trainable params
238 M     Total params
955.192   Total estimated model params size (MB)
561       Modules in train mode
0         Modules in eval mode
Epoch 0:   0%|                                                                                                                                                                               | 0/59 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/workspace/auto-avsr/train.py", line 212, in <module>
    cli_main()
  File "/workspace/auto-avsr/train.py", line 207, in cli_main
    trainer.fit(model=modelmodule, datamodule=datamodule, ckpt_path=args.ckpt_path)
  File "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 561, in fit
    call._call_and_handle_interrupt(
  File "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 599, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1012, in _run
    results = self._run_stage()
  File "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1056, in _run_stage
    self.fit_loop.run()
  File "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 455, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 306, in advance
    batch, _, __ = next(data_fetcher)
  File "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/fetchers.py", line 134, in __next__
    batch = super().__next__()
  File "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/fetchers.py", line 61, in __next__
    batch = next(self.iterator)
  File "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/utilities/combined_loader.py", line 341, in __next__
    out = next(self._iterator)
  File "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/utilities/combined_loader.py", line 78, in __next__
    out[i] = next(self.iterators[i])
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 708, in __next__
    data = self._next_data()
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1480, in _next_data
    return self._process_data(data)
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1505, in _process_data
    data.reraise()
  File "/opt/conda/lib/python3.10/site-packages/torch/_utils.py", line 733, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 349, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
    data = self.dataset[possibly_batched_index]
  File "/workspace/auto-avsr/datamodule/data_module.py", line 103, in __getitem__
    return [self.dataset[subidx] for subidx in self.batches[idx]]
  File "/workspace/auto-avsr/datamodule/data_module.py", line 103, in <listcomp>
    return [self.dataset[subidx] for subidx in self.batches[idx]]
  File "/workspace/auto-avsr/datamodule/av_dataset.py", line 65, in __getitem__
    video = self.video_transform(video)
  File "/workspace/auto-avsr/datamodule/transforms.py", line 110, in __call__
    return self.video_pipeline(sample)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/transforms.py", line 673, in forward
    i, j, h, w = self.get_params(img, self.size)
  File "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/transforms.py", line 632, in get_params
    raise ValueError(f"Required crop size {(th, tw)} is larger than input image size {(h, w)}")
ValueError: Required crop size (88, 88) is larger than input image size (82, 224)

[rank0]: Traceback (most recent call last):
[rank0]:   File "/workspace/auto-avsr/train.py", line 212, in <module>
[rank0]:     cli_main()
[rank0]:   File "/workspace/auto-avsr/train.py", line 207, in cli_main
[rank0]:     trainer.fit(model=modelmodule, datamodule=datamodule, ckpt_path=args.ckpt_path)
[rank0]:   File "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 561, in fit
[rank0]:     call._call_and_handle_interrupt(
[rank0]:   File "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank0]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank0]:   File "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
[rank0]:     return function(*args, **kwargs)
[rank0]:   File "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 599, in _fit_impl
[rank0]:     self._run(model, ckpt_path=ckpt_path)
[rank0]:   File "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1012, in _run
[rank0]:     results = self._run_stage()
[rank0]:   File "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1056, in _run_stage
[rank0]:     self.fit_loop.run()
[rank0]:   File "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
[rank0]:     self.advance()
[rank0]:   File "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 455, in advance
[rank0]:     self.epoch_loop.run(self._data_fetcher)
[rank0]:   File "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
[rank0]:     self.advance(data_fetcher)
[rank0]:   File "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 306, in advance
[rank0]:     batch, _, __ = next(data_fetcher)
[rank0]:   File "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/fetchers.py", line 134, in __next__
[rank0]:     batch = super().__next__()
[rank0]:   File "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/fetchers.py", line 61, in __next__
[rank0]:     batch = next(self.iterator)
[rank0]:   File "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/utilities/combined_loader.py", line 341, in __next__
[rank0]:     out = next(self._iterator)
[rank0]:   File "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/utilities/combined_loader.py", line 78, in __next__
[rank0]:     out[i] = next(self.iterators[i])
[rank0]:   File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 708, in __next__
[rank0]:     data = self._next_data()
[rank0]:   File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1480, in _next_data
[rank0]:     return self._process_data(data)
[rank0]:   File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1505, in _process_data
[rank0]:     data.reraise()
[rank0]:   File "/opt/conda/lib/python3.10/site-packages/torch/_utils.py", line 733, in reraise
[rank0]:     raise exception
[rank0]: ValueError: Caught ValueError in DataLoader worker process 0.
[rank0]: Original Traceback (most recent call last):
[rank0]:   File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 349, in _worker_loop
[rank0]:     data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
[rank0]:   File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
[rank0]:     data = self.dataset[possibly_batched_index]
[rank0]:   File "/workspace/auto-avsr/datamodule/data_module.py", line 103, in __getitem__
[rank0]:     return [self.dataset[subidx] for subidx in self.batches[idx]]
[rank0]:   File "/workspace/auto-avsr/datamodule/data_module.py", line 103, in <listcomp>
[rank0]:     return [self.dataset[subidx] for subidx in self.batches[idx]]
[rank0]:   File "/workspace/auto-avsr/datamodule/av_dataset.py", line 65, in __getitem__
[rank0]:     video = self.video_transform(video)
[rank0]:   File "/workspace/auto-avsr/datamodule/transforms.py", line 110, in __call__
[rank0]:     return self.video_pipeline(sample)
[rank0]:   File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py", line 250, in forward
[rank0]:     input = module(input)
[rank0]:   File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/transforms.py", line 673, in forward
[rank0]:     i, j, h, w = self.get_params(img, self.size)
[rank0]:   File "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/transforms.py", line 632, in get_params
[rank0]:     raise ValueError(f"Required crop size {(th, tw)} is larger than input image size {(h, w)}")
[rank0]: ValueError: Required crop size (88, 88) is larger than input image size (82, 224)
